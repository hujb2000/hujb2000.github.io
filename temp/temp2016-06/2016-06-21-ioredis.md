---
layout: post
title:  "ioredis"
date:   2016-06-21 13:35:30
categories: allen.hu update
---

#  ioredis

ioredis is a robust, full-featured Redis client that is used in the world's biggest online commerce company Alibaba and many other awesome companies.

opts.
parser :  hiredis | javascript
dropBufferSupport: be enabled when "hiredis" is used. Refer to [https://github.com/luin/ioredis/wiki/Improve-Performance](https://github.com/luin/ioredis/wiki/Improve-Performance) for more details.


Hiredis & Javascript

* Hiredis
hiredis: hiredis is a native C module that is used by redis-cli. It's very fast and stable. To use hiredis as the parser, install "hiredis" module in your project (npm install hiredis) and ioredis will use it by default.

What's more , hiredis has a limitation on the depth(<=7) of the replies.

* Javascript

javascript parser is a built-in parser, so you don't need to install any dependencies to use it. It'll be used if hiredis module is not installed o

Thanks to the V8 engine, javascript parser is almost as fast as hiredis parser in many cases. However, when it comes to large replies, javascript parser will be very slow. It may block your application when fetching a list with two million members using lrange command which shouldn't be a problem for hiredis parser.

* dropBufferSupport option

So ioredis support dropBufferSupport option since v2.0.0. By default it's disabled. When it's enabled, ioredis will force the parser to return strings instead of buffers. However, that means all binary methods will not work anymore. You will get an error when using them:

```
var redis = new Redis({ dropBufferSupport: true });
redis.getBuffer('foo', function (err) {
  // err will be "*Buffer methods are not available..."
});
```

## API

## Migrating from node_redis

## Medis

Medis is a beautiful, easy-to-use Redis management application built on the modern web with Electron, React, and Redux. It's powered by many awesome Node.js modules, especially ioredis and ssh2.

* Running Locally

npm  install
npm run dev

* Build Medis

npm install
npm run deploy

## Pipelining

If you want to send a batch of commands (e.g. > 5), you can use pipelining to queue the commands in memory and then send them to Redis all at once. This way the performance improves by 50%~300% (See benchmark section).

## Transaction

Most of the time, the transaction commands multi & exec are used together with pipeline. Therefore, when multi is called, a Pipeline instance is created automatically by default, so you can use multi just like pipeline:

```
redis.multi().set('foo', 'bar').get('foo').exec(function (err, results) {
  // results === [[null, 'OK'], [null, 'bar']]
});

## Lua Scripting

```
var redis = new Redis();

// This will define a command echo:
redis.defineCommand('echo', {
  numberOfKeys: 2,
  lua: 'return {KEYS[1],KEYS[2],ARGV[1],ARGV[2]}'
});

// Now `echo` can be used just like any other ordinary command,
// and ioredis will try to use `EVALSHA` internally when possible for better performance.
redis.echo('k1', 'k2', 'a1', 'a2', function (err, result) {
  // result === ['k1', 'k2', 'a1', 'a2']
});

// `echoBuffer` is also defined automatically to return buffers instead of strings:
redis.echoBuffer('k1', 'k2', 'a1', 'a2', function (err, result) {
  // result[0] === new Buffer('k1');
});

// And of course it works with pipeline:
redis.pipeline().set('foo', 'bar').echo('k1', 'k2', 'a1', 'a2').exec();

* Streamify Scanning

```
var redis = new Redis();
// Create a readable stream (object mode)
var stream = redis.scanStream();
var keys = [];
stream.on('data', function (resultKeys) {
  // `resultKeys` is an array of strings representing key names
  for (var i = 0; i < resultKeys.length; i++) {
    keys.push(resultKeys[i]);
  }
});
stream.on('end', function () {
  console.log('done with the keys: ', keys);
});

```

## Read-write splitting

```
```

## Transaction and pipeline in Cluster mode

Almost all features that are supported by Redis are also supported by Redis.Cluster, e.g. custom commands, transaction and pipeline. However there are some differences when using transaction and pipeline in Cluster mode:





